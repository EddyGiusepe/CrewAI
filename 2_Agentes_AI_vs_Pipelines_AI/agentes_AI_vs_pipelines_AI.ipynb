{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\"><font color=\"red\">Agentes de IA vs. Pipelines de IA - Um guia prático para programar sua aplicação de LLM</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"pink\">Senior Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link de estudo [aqui](https://datavizandai.github.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos o ``CrewAI`` para criar aplicativos que demonstram como escolher a arquitetura certa para sua aplicação ``LLM``.\n",
    "\n",
    "Podemos pensar em um ``agente de IA`` como um ``LLM`` com acesso a ferramentas externas; ele funciona em um loop, tomando decisões sobre como se comportar e quais ferramentas usar em cada iteração.\n",
    "\n",
    "Ao fazer isso, o agente pode resolver problemas muito mais complexos do que um aplicativo ``LLM`` convencional. (Expliquei como construir um agente desse tipo do zero no artigo [Como construir um agente ReAct AI com Claude 3.5 e Python](https://ai.gopubby.com/how-to-build-a-react-ai-agent-with-claude-3-5-and-python-95423f798640))\n",
    "\n",
    "``Agentes de IA`` são poderosos e estão muito além de um aplicativo de bate-papo convencional. Mas nem sempre são a solução certa.\n",
    "\n",
    "<font color=\"orange\">Às vezes, uma sequência de funções mais convencionais é mais apropriada. Podemos pensar nesse tipo de aplicação como um ``pipeline``, onde uma solução é desenvolvida passando a saída de uma função como entrada para a próxima.</font>\n",
    "\n",
    "Neste artigo, exploraremos o uso de ``agentes`` e ``pipelines`` de IA e para quais tipos de aplicações eles são mais adequados. Usaremos a estrutura de código aberto ``CrewAI`` para criar a lógica do ``LLM`` e construir um front-end simples em ``Streamlit`` para um aplicativo online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"gree\">Aplicativos para agentes e aplicativos para pipelines</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pensar em alguns aplicativos diferentes. \n",
    "\n",
    "Um cliente acessa o site de um fabricante para resolver um problema com sua máquina de lavar. Ele é recebido por um ``agente de IA`` que quer ajudar. Qual é a marca e o modelo da máquina? Quais são os sintomas? As roupas ainda estão sujas? Há água no chão? Ela não centrifuga?\n",
    "\n",
    "Há uma série de perguntas que o agente pode fazer para resolver qualquer problema do cliente. ``E as perguntas subsequentes dependerão das respostas anteriores.``\n",
    "\n",
    "Nesse caso, um ``agente de IA`` é uma ótima solução. Ele precisa trabalhar em loop, coletando informações, até que esteja em condições de sugerir uma solução ou, caso fique sem ideias, repassar o problema a um operador humano.\n",
    "\n",
    "O funcionamento deste tipo de agente está representado no diagrama abaixo.\n",
    "\n",
    "![](https://datavizandai.github.io/assets/images/agentpipeline/reactflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Aqui está outro cenário.``\n",
    "\n",
    "A diretora de vendas de uma pequena empresa que administra cafeterias em Londres quer produzir um relatório sobre o desempenho de várias filiais. Ela precisa verificar regularmente como o desempenho difere entre as lojas localizadas no distrito financeiro da City e o West End, mais voltado para o turismo e o varejo. Ela tem planilhas detalhando as vendas de cada filial. Ela quer consolidar os números e escrever um relatório para sua diretoria, que inclua gráficos de fácil compreensão que mostrem o desempenho relativo de cada cafeteria.\n",
    "\n",
    "Nesse caso, o diretor poderia usar um aplicativo LLM para combinar os números de vendas mensais em uma única entidade, escrever um comentário sobre o desempenho dos diferentes pontos de venda, produzir os gráficos apropriados e combinar esses elementos em um único relatório. O processo é o mesmo todos os meses e a única variável são os valores nas planilhas. Portanto, embora o conteúdo do relatório varie, o processo é o mesmo.\n",
    "\n",
    "``Diferentemente do exemplo agêntico, este é um fluxo sequencial simples.``\n",
    "\n",
    "\n",
    "![](https://datavizandai.github.io/assets/images/agentpipeline/pipelineflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ``agente de IA`` é a solução ideal para o primeiro problema. Dispondo de informações adequadas sobre o funcionamento da máquina de lavar, seus potenciais modos de falha e os sintomas dessas falhas, o agente pode buscar informações de forma inteligente e formular novas perguntas em resposta às informações do cliente até encontrar uma solução. Para esse tipo de problema, o ``agente de IA`` oferece uma solução flexível e inteligente.\n",
    "\n",
    "Um relatório de vendas é um assunto diferente. Os números de vendas mudam e pode ser que um relatório encontre diferenças no desempenho dependendo da época do ano e da frequência de turistas ou trabalhadores de escritório.\n",
    "\n",
    "Portanto, embora seja necessária uma visão inteligente desses números variáveis, os processos para a criação do relatório são os mesmos. Consolidar os números; analisar os resultados de vendas; criar os gráficos; e, por fim, redigir o relatório completo.\n",
    "\n",
    "Você pode escrever um prompt para um agente que o oriente a seguir as etapas necessárias, mas um resultado mais consistente pode vir da criação de uma série de tarefas em que a saída de uma alimenta a entrada da próxima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"yellow\">CrewAI</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O ``CrewA``I está disponível em duas versões:`` Enterprise`` e ``Open Source``. Usaremos a versão de código aberto aqui, portanto, não há chaves de API ou custos envolvidos.\n",
    "\n",
    "A instalação do ``CrewAI`` é o que você esperaria, embora, como usaremos ferramentas externas, precisamos adicionar essa funcionalidade também.\n",
    "\n",
    "```\n",
    "pip install crewai crewai-tools\n",
    "```\n",
    "Criaremos uma ferramenta para o ``CrewAI`` usar com base na ``biblioteca Wikipedia do PyPi``, então também precisaremos instalá-la.\n",
    "\n",
    "```\n",
    "pip install wikipedia\n",
    "```\n",
    "\n",
    "O primeiro aplicativo que desenvolveremos se chama ``Wikipédia Inteligente``. Ele realizará uma consulta e, em seguida, usará a ferramenta ``Wikipédia`` para encontrar uma resposta. Ele fará isso raciocinando sobre a consulta, calculando o que precisa descobrir, realizando as buscas apropriadas e analisando os resultados antes de fornecer uma resposta. Se isso parece complicado, não se preocupe, não é."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\">`Agente:` Wikipédia inteligente</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Tools</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos especificar a ``ferramenta Wikipédia``. Uma ferramenta é uma função que um agente CrewAI pode chamar, se necessário. Ela executa uma tarefa e retorna um valor. A maneira mais simples de definir uma ferramenta é com um ``decorador``. Então, a próxima célula é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tools import tool\n",
    "import wikipedia\n",
    "\n",
    "@tool(\"wikipedia_lookup\")\n",
    "def wikipedia_lookup(q: str) -> str:\n",
    "    \"\"\"Olhe para uma consulta no Wikipedia e retorne o resultado\"\"\"\n",
    "    return wikipedia.page(q).summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após as importações, temos uma função simples que recebe um parâmetro de string, o envia para a ``Wikipédia`` e retorna um resumo de uma página da ``Wikipédia``. Observe que incluímos uma descrição da função e dicas de tipo para o parâmetro e o valor de retorno. Isso ajuda o ``CrewAI`` a entender como usar a ferramenta.\n",
    "\n",
    "Agora chegamos à parte principal da aplicação: definimos o ``agente`` que fará o trabalho para nós e a tarefa que queremos que ele execute, e então criamos e executamos a equipe. ``Essa equipe combina agentes e tarefas em algo que pode ser executado.`` Em nossa primeira aplicação, trata-se de um único agente e uma única tarefa, mas mais adiante veremos equipes mais complexas ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Agentes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos primeiro analisar o agente. O código a seguir cria uma variável de agente chamada ``researcher_agent``. Ela especifica uma ``função``, um ``objetivo``, uma ``história de fundo`` e uma ``lista de ferramentas`` que o agente pode usar. Ela também especifica o modelo de LLM a ser usado. Portanto, a próxima célula é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_agent = Agent(\n",
    "        role=\"Pesquisador\",\n",
    "        goal=\"Você pesquisa tópicos usando Wikipedia e relata os resultados\",\n",
    "        backstory=\"Você é um escritor e editor experiente\",\n",
    "        tools=[wikipedia_lookup],\n",
    "        llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0) # \"gpt-4o\"   ou  \"gpt-4o-mini\"  ou  \"gpt-3.5-turbo-0125\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitos outros atributos podem ser especificados para um Agente, mas estes são os básicos. O ``LLM`` e as ferramentas são bastante óbvios, sendo itens sobre os quais você deve ser específico. Mas é compreensível pensar que ``role`` , ``goal`` e ``backstory`` são mais como encantamentos mágicos do que requisitos de programação. No entanto, como você pode esperar, essas strings são usadas quando o ``CrewAI`` constrói ``prompts`` para o ``LLM``.\n",
    "\n",
    "Então, isso é um Agente: algumas coisas que informam ao ``LLM`` sua finalidade, uma lista de ferramentas e um modelo de ``LLM``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Tasks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A próxima etapa é a ``task``. Ela nos diz o que o agente precisa fazer e, para nossos propósitos, envolverá responder a uma consulta. Quando criarmos um aplicativo adequado, solicitaremos uma consulta ao usuário, mas este é um protótipo do ``Jupyter Notebook``, então, para facilitar, codificaremos a consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Nestes dias que ex-presidente foi preso no Perú?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa não é uma pergunta que pode ser respondida diretamente em uma página da Wikipédia. Será necessário algum ``raciocínio``.\n",
    "\n",
    "E aqui está a especificação da tarefa que incorporará esta consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = Task(\n",
    "    description=query,\n",
    "    expected_output='Um texto curto baseado nas informações da ferramenta.',\n",
    "    agent=researcher_agent,\n",
    "    tools=[wikipedia_lookup]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A descrição da tarefa é a consulta, explicamos qual será a saída esperada (``essa é outra sequência mágica que terminará em um prompt``), associamos a tarefa a um agente e listamos as ferramentas que podem ser usadas.\n",
    "\n",
    "Agora amarramos tudo isso com uma crew (equipe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Crews</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[researcher_agent],\n",
    "    tasks=[task1],\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclui uma lista de ``agentes`` e uma lista de ``tarefas``. Neste caso, uma tarefa e um agente. Quando o ``verbose`` sinalizador for definido, o ``CrewAI`` mostrará seu funcionamento — veremos isso em breve.\n",
    "\n",
    "Agora tudo o que precisamos fazer é executar tudo e analisar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O ex-presidente do Peru, José Pedro Castillo, foi preso em 7 de dezembro de 2022, após tentar dissolver ilegalmente o Congresso e governar por decreto. Ele foi destituído do cargo pelo Congresso e detido sob acusações de sedição e alta traição.\n",
      "\n",
      "\n",
      "\n",
      "Descrição da tarefa: Nestes dias que ex-presidente foi preso no Perú?\n",
      "Resumo da tarefa: Nestes dias que ex-presidente foi preso no Perú?...\n",
      "Raw Output: O ex-presidente do Peru, José Pedro Castillo, foi preso em 7 de dezembro de 2022, após tentar dissolver ilegalmente o Congresso e governar por decreto. Ele foi destituído do cargo pelo Congresso e detido sob acusações de sedição e alta traição.\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff()\n",
    "print(result)\n",
    "print(\"\\n\\n\")\n",
    "# Acessando a saída da tarefa:\n",
    "task_output = task1.output\n",
    "\n",
    "print(f\"Descrição da tarefa: {task_output.description}\")\n",
    "print(f\"Resumo da tarefa: {task_output.summary}\")\n",
    "print(f\"Raw Output: {task_output.raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Você pode ver que o `CrewAI` segue um processo muito semelhante ao de um agente. Ele raciocina sobre sua resposta, coleta as informações apropriadas e, em seguida, responde com uma resposta adequada.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"pink\">`Pipeline:` Wikipédia inteligente para crianças</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar um `pipeline`, definimos mais agentes e mais tarefas e, então, criamos uma equipe que se juntará a eles de maneira sensata.\n",
    "\n",
    "O novo aplicativo se baseia no anterior. Chama-se `Wikipédia para Crianças` e, novamente, busca algo na `Wikipédia`, mas depois traduz para um texto adequado para jovens leitores e o encurta para algumas centenas de palavras.\n",
    "\n",
    "Vamos dar uma olhada no código dos agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "from crewai.tools import tool\n",
    "import wikipedia\n",
    "\n",
    "@tool(\"wikipedia_lookup\")\n",
    "def wikipedia_lookup(q: str) -> str:\n",
    "    \"\"\"Olhe para uma consulta no Wikipedia e retorne o resultado\"\"\"\n",
    "    return wikipedia.page(q).summary\n",
    "\n",
    "\n",
    "researcher_agent = Agent(\n",
    "        role=\"Pesquisador\",\n",
    "        goal=\"Você pesquisa tópicos usando Wikipedia e relata os resultados\",\n",
    "        backstory=\"Você é um escritor e editor experiente\",\n",
    "        tools=[wikipedia_lookup],\n",
    "        llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0) # \"gpt-4o\"   ou  \"gpt-4o-mini\"  ou  \"gpt-3.5-turbo-0125\"\n",
    "    )\n",
    "writer_agent = Agent(\n",
    "        role=\"Escritor\",\n",
    "        goal=\"Você reescreve artigos para que sejam adequados para leitores jovens\",\n",
    "        backstory=\"Você é um escritor e editor experiente\",\n",
    "        llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0) # \"gpt-4o\"   ou  \"gpt-4o-mini\"  ou  \"gpt-3.5-turbo-0125\"\n",
    "    )\n",
    "editor_agent = Agent(\n",
    "        role=\"Editor\",\n",
    "        goal=\"Você garante que o texto que você recebe é gramaticalmente correto e do comprimento correto\",\n",
    "        backstory=\"Você é um escritor e editor experiente\",\n",
    "        llm=ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0) # \"gpt-4o\"   ou  \"gpt-4o-mini\"  ou  \"gpt-3.5-turbo-0125\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode ver que agora temos três agentes. Os dois segundos são o `writer_agent` o `editor_agent`. As goal strings indicam sua finalidade e, embora também exijam um `LLM`, não precisam usar a ferramenta Wikipédia.\n",
    "\n",
    "Ter os agentes é aceitável, mas precisamos especificar quais tarefas eles precisam executar. Aqui está a célula de código para as tarefas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Nestes mês de abril do 2025 que ex-presidente foi preso no Perú?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = Task(\n",
    "    description=query,\n",
    "    expected_output='Um pequeno texto baseado na saída da ferramenta',\n",
    "    agent=researcher_agent,\n",
    "    tools=[wikipedia_lookup]\n",
    ")\n",
    "task2 = Task(\n",
    "    description=\"Reescreva o texto para ser adequado para um leitor de 10 anos\",\n",
    "    expected_output='Um pequeno texto baseado na saída da ferramenta',\n",
    "    agent=writer_agent,\n",
    ")\n",
    "task3 = Task(\n",
    "    description=\"Edite o texto para garantir que esteja gramaticalmente correto e não mais de 500 palavras\",\n",
    "    expected_output='Um pequeno texto baseado na saída da ferramenta',\n",
    "    agent=editor_agent,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira tarefa é como a anterior, mas a segunda e a terceira instruem os agentes a alterar o texto original para algo adequado para um leitor de `10 anos`, garantindo que esteja gramaticalmente correto e não tenha mais de `500 palavras`. Observe que os agentes apropriados são especificados em cada tarefa e que a ferramenta `Wikipédia` é necessária apenas para a primeira tarefa.\n",
    "\n",
    "Agora precisamos criar uma equipe e executá-la. Aqui está o código para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m Maximum iterations reached. Requesting final answer.\u001b[00m\n",
      "Raw Output: Em abril de 2025, o ex-presidente do Peru, Pedro Castillo, foi preso. Ele foi detido pela polícia em conexão com acusações de corrupção e abuso de poder, após ter sido destituído do cargo em dezembro de 2022. A prisão de Castillo gerou protestos e uma série de reações políticas no país, refletindo a polarização que caracteriza a política peruana nos últimos anos. \n",
      "\n",
      "A detenção de Castillo não apenas acendeu a indignação de seus apoiadores, mas também provocou uma onda de manifestações em várias cidades do Peru. Os protestos foram marcados por uma mistura de apoio ao ex-presidente e críticas à forma como o governo atual tem lidado com a crise política. Muitos manifestantes exigiram a libertação de Castillo, argumentando que sua prisão era uma manobra política para silenciar a oposição.\n",
      "\n",
      "Por outro lado, os opositores de Castillo celebraram sua prisão, considerando-a um passo necessário para restaurar a ordem e a integridade nas instituições peruanas. A situação se tornou um ponto de discórdia entre diferentes grupos políticos, evidenciando a divisão profunda que permeia a sociedade peruana. A polarização política, que já era evidente antes da prisão, se intensificou, levando a um clima de tensão e incerteza no país.\n",
      "\n",
      "Além disso, a prisão de Castillo levantou questões sobre a justiça e a imparcialidade do sistema judicial peruano. Críticos apontaram que a detenção poderia ser vista como uma violação dos direitos humanos, enquanto defensores da ação policial argumentaram que era uma medida necessária para combater a corrupção. Essa dualidade de opiniões reflete a complexidade da situação política no Peru, onde a confiança nas instituições governamentais está em baixa.\n",
      "\n",
      "A repercussão da prisão de Castillo também se estendeu para o cenário internacional, com observadores e analistas políticos acompanhando de perto os desdobramentos. A comunidade internacional expressou preocupações sobre a estabilidade política no Peru e o impacto que isso poderia ter na democracia do país. A situação continua a evoluir, com a expectativa de que novos desdobramentos ocorram nas próximas semanas.\n",
      "\n",
      "Em resumo, a prisão de Pedro Castillo em abril de 2025 não apenas marcou um capítulo significativo na política peruana, mas também expôs as fissuras existentes na sociedade. A polarização política, as manifestações populares e as reações dos líderes políticos são indicativos de um país em busca de um caminho para a estabilidade e a justiça. O futuro do Peru permanece incerto, à medida que os cidadãos e os políticos navegam por um cenário complexo e desafiador.\n"
     ]
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents=[researcher_agent, writer_agent, editor_agent],\n",
    "    tasks=[task1, task2, task3],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "\n",
    "print(f\"Raw Output: {result.raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir a equipe, simplesmente listamos os agentes e as tarefas na ordem em que precisam ser executadas. Observe que há uma pequena alteração na forma como o resultado é recuperado. Não usamos a saída de uma tarefa, mas sim o resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\">Conclusão: Agentes de IA vs. Pipelines de IA em aplicações de LLM</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As duas abordagens diferem na maneira como lidam com tarefas, tomada de decisões e interação.\n",
    "\n",
    "Os `agentes` são autônomos, podem tomar decisões e são potencialmente interativos. Nessa abordagem, o `LLM` atua como um \"agente\" capaz de compreender solicitações potencialmente complexas do usuário e adaptar seu comportamento para atingir objetivos específicos. Exemplos de uso incluem assistentes virtuais conversacionais (como no aplicativo que vimos) ou agentes autônomos de atendimento ao cliente.\n",
    "\n",
    "`Os agentes podem lidar com tarefas abertas e manter o contexto ao longo do tempo, tornando-os ideais para aplicativos complexos e interativos.`\n",
    "\n",
    "Os `pipelines de IA` , por outro lado, seguem um processo linear e determinístico com etapas predefinidas para tarefas como processamento de dados. São estruturados e adequados para aplicações que envolvem tarefas repetitivas e bem definidas, como classificação de texto, processamento de documentos ou transformação de dados.\n",
    "\n",
    "Os pipelines de IA são modulares, escaláveis ​​e, como normalmente consistem em tarefas bem definidas, são mais previsíveis do que o comportamento mais aberto dos agentes.\n",
    "\n",
    "Os agentes podem ser projetados para imitar pipelines estruturando seus prompts como uma sequência de tarefas, mas o resultado pode ser menos previsível ou consistente. Portanto, quando um pipeline pode ser usado, essa pode ser a melhor abordagem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
